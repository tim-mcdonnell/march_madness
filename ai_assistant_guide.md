# AI Assistant Guide - NCAA March Madness Predictor

This guide is designed to help AI coding assistants understand the structure, patterns, and workflows of the NCAA March Madness Predictor project. It provides essential context about the codebase organization to help you generate correct, compatible code without requiring the entire codebase as context.

> **Documentation Standards**: When writing or modifying documentation, please follow our [Documentation Guide](documentation_guide.md) which outlines our documentation structure, standards, and best practices.

## 1. Project Overview

The NCAA March Madness Predictor is a data science project that builds optimal March Madness brackets using historical NCAA men's basketball data. It uses a pipeline-based architecture to:

1. Collect and process 22+ years of NCAA basketball data from the sportsdataverse repository
2. Engineer features that predict tournament success
3. Train neural network models for game outcome prediction
4. Generate optimized brackets with visualizations

### Key Technology Stack

- **Python 3.11+**: Core programming language
- **uv**: Package manager and environment tool
- **Polars**: High-performance DataFrame library (primary data manipulation tool)
- **PyTorch**: Deep learning framework
- **Plotly Dash**: Interactive visualization
- **Parquet/PyArrow**: Data storage format
- **YAML**: Configuration files

## 2. Directory Structure & Purpose

```
march_madness/
├── config/                 # YAML configuration files
│   └── pipeline_config.yaml # Main pipeline configuration
├── data/                   # Data storage (gitignored)
│   ├── raw/                # Original unmodified data
│   ├── processed/          # Cleaned and transformed data
│   ├── master/             # Master data files for teams
│   └── features/           # Engineered features
├── docs/                   # Documentation files
├── models/                 # Saved model files
├── reports/                # Analysis reports and visualizations
│   ├── findings/           # Markdown reports of analysis findings 
│   └── figures/            # Visualizations generated from analysis
├── src/                    # Source code
│   ├── data/               # Data processing modules
│   ├── eda/                # Exploratory data analysis scripts
│   ├── features/           # Feature engineering
│   ├── models/             # Model code
│   ├── pipeline/           # Pipeline framework
│   └── visualization/      # Visualization code
├── tests/                  # Test code
├── .github/                # GitHub configurations
├── run_pipeline.py         # Main pipeline execution script
└── pyproject.toml          # Project configuration and dependencies
```

## 3. Core Modules & Relationships

### 3.1 Pipeline Framework (`src/pipeline/`)

The backbone of the project is the pipeline framework that orchestrates data processing, feature engineering, model training, and prediction:

- **`cli.py`**: Command-line interface for the pipeline
- **`config.py`**: Configuration management (loading, validation)
- **`data_stage.py`**: Implementation of the data collection stage
- **`data_management.py`**: Utilities for data organization and cleaning
- **`master_data_stage.py`**: Creation and maintenance of master data for teams and other entities

The pipeline is designed to be modular, with separate stages that can run independently:
1. **Data Collection**: Fetches and stores raw data
2. **Master Data**: Creates foundational reference tables for team information and other entities
3. **Data Processing**: Cleans and transforms raw data
4. **Feature Engineering**: Creates model features
5. **Model Training**: Trains prediction models
6. **Bracket Generation**: Creates optimized brackets

### 3.2 Data Processing (`src/data/`)

This module handles the loading, cleaning, and transformation of NCAA basketball data:

- **Data Sources**: Data is sourced exclusively from sportsdataverse's hoopR-mbb-data repository
- **Data Categories**: play_by_play, player_box, schedules, team_box
- **Data Format**: Parquet files, loaded using Polars (not Pandas)
- **Data Years**: 2003-2025 (22+ years of historical data)

### 3.3 Team Master Data (`data/master/`)

This is a critical foundation for all data processing in the project:

- **Purpose**: Provides a single source of truth for team information to address inconsistencies across raw data files
- **Content**: Contains team IDs, locations, names, and the seasons in which they appear
- **Creation**: Generated by scanning all raw data files and enriching with ESPN API data
- **Files**:
  - `team_master_base.parquet`: Skeleton data with team IDs and seasons
  - `team_master.parquet`: Fully enriched data with team locations and names
- **Important Note**: When joining with this data, always join **only on `team_id` and `season`**. Team locations and names can vary from year to year in NCAA data, and using consistent joining ensures data integrity.

**Example correct join pattern**:
```python
import polars as pl

# Load team master data
team_master = pl.read_parquet("data/master/team_master.parquet")

# Load processed data
processed_data = pl.read_parquet("data/processed/team_box/2023.parquet")

# Correct join - only use team_id and season
enriched_data = processed_data.join(
    team_master,
    on=["team_id", "season"],
    how="left"
)
```

### 3.4 Exploratory Data Analysis (`src/eda/`)

This module contains scripts for analyzing data and generating insights:

- Python scripts organized by analysis topic (e.g., `regular_vs_tournament_analysis.py`)
- Each script follows modular structure defined in `src/eda/README.md`
- Scripts generate markdown reports in `reports/findings/`
- Visualizations are saved to `reports/figures/`
- Analysis follows consistent methodology and reporting structure

### 3.5 Feature Engineering (`src/features/`)

Transforms processed data into features for model training:

- **Feature System Structure**: 
  - Features are implemented as classes that inherit from `BaseFeature`
  - Features are organized by category in separate directories
  - Features are automatically discovered and registered at runtime
  - Each feature has a unique ID and is part of a category
  
- **Key Components**:
  - `src/features/core/base.py`: Contains the `BaseFeature` abstract base class
  - `src/features/core/registry.py`: Handles feature registration and discovery
  - `src/features/core/loader.py`: Loads feature data and manages calculation
  - `src/features/core/data_manager.py`: Manages feature data storage
  - `src/pipeline/feature_stage.py`: Integrates features with the pipeline

- **Feature Categories**:
  - `team_performance/`: Win percentages, point differentials, etc. (T*)
  - `shooting/`: Shooting and scoring metrics (S*)
  - `advanced_team/`: Advanced team metrics (A*)
  - Plus additional categories for different feature types
  
- **Feature Implementation**:
  ```python
  from src.features.core.base import BaseFeature
  
  class EffectiveFieldGoalPercentage(BaseFeature):
      """Feature class for Effective Field Goal Percentage."""
      
      id = "S01"  # Unique identifier
      name = "Effective Field Goal Percentage"  # Human-readable name
      category = "shooting"  # Category (matches directory name)
      description = "Field goal percentage adjusted for three-pointers"
      
      def calculate(self, data):
          """Calculate the feature from input data."""
          # Implementation
          return result
  ```

- **Feature Storage**:
  - Features are stored in `data/features/{category}_metrics.parquet`
  - Combined features are stored in `data/features/combined/full_feature_set.parquet`

- **Feature Documentation**:
  - Complete feature list in `FEATURES.md` at project root
  - Detailed feature documentation in `docs/features/{category}/{ID}_{feature_name}.md`
  - Feature system overview in `docs/features/index.md`

### 3.6 Models (`src/models/`)

Implements neural network models for game outcome prediction:

- PyTorch-based neural network architecture
- Training utilities
- Evaluation metrics
- Prediction generation

### 3.7 Visualization (`src/visualization/`)

Creates visualizations for insights and bracket presentation:

- Plotly/Dash-based interactive visualizations
- Bracket visualization utilities
- Performance metric plotting

## 4. Code Conventions & Patterns

### 4.1 Naming Conventions

- **Files**: Snake case (`feature_engineering.py`)
- **Classes**: Pascal case (`DataProcessor`)
- **Functions/Methods**: Snake case (`process_data()`)
- **Variables**: Snake case (`team_stats`)
- **Constants**: Uppercase with underscores (`BASE_URL`)

### 4.2 Type Hints & Documentation

- All functions should include type hints
- Documentation follows Google-style docstrings
- Complex logic includes inline comments

```python
def calculate_team_efficiency(
    team_data: pl.DataFrame,
    season: int
) -> pl.DataFrame:
    """
    Calculate offensive and defensive efficiency ratings for teams.
    
    Args:
        team_data: DataFrame containing team statistics
        season: Basketball season year (e.g., 2023)
        
    Returns:
        DataFrame with added efficiency columns
    """
    # Implementation...
```

### 4.3 Data Processing Standards

- **Primary DataFrame Library**: Use Polars, not Pandas
- **Schema Enforcement**: All DataFrames use explicit schemas
- **Error Handling**: Use explicit try/except blocks with informative error messages
- **File Paths**: Generated using pathlib.Path, not string concatenation

```python
# CORRECT: Using Polars with schema
import polars as pl
from pathlib import Path

# Define schema
team_schema = {
    "team_id": pl.Int64,
    "team_name": pl.Utf8,
    "points": pl.Float64,
    # Other fields...
}

# Load data with proper path handling
file_path = Path("data/processed") / f"team_stats_{season}.parquet"
team_stats = pl.read_parquet(file_path, schema=team_schema)

# INCORRECT: Avoid these patterns
# import pandas as pd
# team_stats = pd.read_csv("data/processed/team_stats_" + str(season) + ".csv")
```

### 4.4 Configuration Management

- Configuration is loaded from YAML files in the `config/` directory
- Use the `config.py` module to access configuration

```python
from src.pipeline.config import load_config

# Load the configuration
config = load_config("config/pipeline_config.yaml")

# Access config values
data_dir = config.data.raw_dir
years = config.data.years
```

### 4.5 Logging

- Use the built-in logging framework
- Log messages should be informative and include context
- Don't use print statements for operational logging

```python
import logging

logger = logging.getLogger(__name__)

# Informative logs with context
logger.info(f"Processing season {season} data")
logger.error(f"Failed to load file: {file_path}")
```

## 5. Key Workflows

### 5.1 Pipeline Execution

The main entry point is `run_pipeline.py` which accepts command-line arguments to configure the pipeline execution:

```bash
# Run the full pipeline
python run_pipeline.py

# Run only specific stages
python run_pipeline.py --stages data features

# Process specific years
python run_pipeline.py --years 2023 2024

# Process specific categories
python run_pipeline.py --categories team_box player_box

# Calculate specific feature categories
python run_pipeline.py --stages features --feature-categories shooting team_performance

# Calculate specific features by ID
python run_pipeline.py --stages features --feature-ids S01 T01

# Overwrite existing feature data
python run_pipeline.py --stages features --overwrite-features

# Clean data before running
python run_pipeline.py --clean-raw       # Clean raw data files only
python run_pipeline.py --clean-processed # Clean processed data files only
python run_pipeline.py --clean-features  # Clean individual feature files (but not combined files)
python run_pipeline.py --clean-models    # Clean model files only
python run_pipeline.py --clean-master    # Clean team master data files (only use this if you need to rebuild the master data)
python run_pipeline.py --clean-all       # Clean all data (but note: team master and combined feature files are not deleted)

# Manually remove combined feature files
rm -rf data/features/combined/

# Custom configuration
python run_pipeline.py --config custom_config.yaml

# Create default config without running
python run_pipeline.py --create-config --no-run

# Set logging level
python run_pipeline.py --log-level DEBUG  # Available levels: DEBUG, INFO, WARNING, ERROR, CRITICAL

# Run EDA script
python -m src.eda.script_name
```

Important Notes About Data Cleaning:
- `--clean-features` removes individual feature category files (e.g., `shooting_metrics.parquet`) but **does not** remove the combined feature set in `data/features/combined/`.
- `--clean-all` cleans all data types but also **does not** remove the combined feature set.
- To completely clean all feature data including the combined feature set, use both `--clean-features` and manually remove the combined directory.

### 5.2 Data Processing Workflow

1. **Data Collection**: 
   - Raw data is downloaded from sportsdataverse GitHub repository
   - Data is stored in `data/raw/{category}/{year}.parquet`

2. **Data Cleaning**:
   - Raw data is processed to handle missing values, outliers, etc.
   - Cleaned data is stored in `data/processed/{category}/{year}.parquet`

3. **Feature Engineering**:
   - Features are created from processed data
   - Feature data is stored in `data/features/{feature_set}/{year}.parquet`

### 5.3 EDA Workflow

1. **Script Creation**:
   - Create a Python script in `src/eda/` for a specific analysis
   - Follow the structure outlined in `src/eda/README.md`
   - For detailed guidance on implementing EDA tasks, refer to the comprehensive `docs/eda_guide.md`

2. **Analysis Execution**:
   - Run the script to analyze data and generate findings
   ```bash
   python -m src.eda.script_name
   ```

3. **Report Generation**:
   - Script automatically creates a markdown report in `reports/findings/`
   - Visualizations are saved to `reports/figures/`
   - Reports follow the template in `reports/findings/README.md`

### 5.4 Model Training Workflow

1. **Data Preparation**:
   - Features are loaded and split into training/validation sets
   - Data is normalized/standardized as needed

2. **Model Training**:
   - PyTorch models are trained with specified hyperparameters
   - Models are evaluated using cross-validation

3. **Model Persistence**:
   - Trained models are saved to the `models/` directory
   - Model metadata is stored alongside model weights

### 5.5 Prediction Workflow

1. **Model Loading**:
   - Trained models are loaded from the `models/` directory

2. **Prediction Generation**:
   - Tournament match-ups are evaluated
   - Win probabilities are calculated

3. **Bracket Creation**:
   - Optimal brackets are generated based on predictions
   - Visualizations are created and saved to `reports/figures/`

## 6. Common Pitfalls & Guidelines

### 6.1 Data Storage Locations

⚠️ **Common Mistake**: Writing data to incorrect locations

✅ **Correct Approach**:
- Raw data: `data/raw/{category}/{year}.parquet`
- Processed data: `data/processed/{category}/{year}.parquet`
- Feature data: `data/features/{feature_set}/{year}.parquet`
- Analysis reports: `reports/findings/{analysis_name}.md`
- Visualizations: `reports/figures/{viz_name}.{ext}`

### 6.2 Data Processing vs. Feature Engineering

⚠️ **Common Mistake**: Mixing data processing with feature engineering or generating placeholder data during processing

✅ **Correct Approach**:
- **Data Processing**: Focus only on cleaning, standardizing, and organizing raw data
  - Only include metrics directly derivable from the raw data
  - Do not calculate advanced metrics or add synthetic/placeholder values
  - Store processed data in `data/processed/`

- **Feature Engineering**: Create derived metrics and features in a separate stage
  - Calculate advanced metrics like efficiency ratings, strength indicators, etc.
  - Apply transformations like normalization, encoding, etc.
  - Store engineered features in `data/features/`

```python
# CORRECT: Clean separation between processing and feature engineering

# Data processing: Clean and standardize raw data
def process_team_data(team_data: pl.DataFrame) -> pl.DataFrame:
    """Process team data without adding synthetic values."""
    return team_data.filter(
        pl.col("team_id").is_not_null()
    ).with_columns([
        pl.col("points").cast(pl.Float64),
        # Only transformations of existing data, no new metrics calculated
    ])

# Feature engineering: Calculate advanced metrics
def engineer_team_features(processed_data: pl.DataFrame) -> pl.DataFrame:
    """Calculate advanced team metrics as features."""
    return processed_data.with_columns([
        # Advanced metrics calculated here
        (pl.col("points") * 100 / pl.col("possessions")).alias("offensive_efficiency"),
        (pl.col("assists") / pl.col("field_goals_made")).alias("assist_rate")
    ])
```

### 6.3 EDA Scripting Standards

⚠️ **Common Mistake**: Creating one-off analysis scripts without proper structure or documentation

✅ **Correct Approach**:
- Follow the template in `src/eda/README.md` for all analysis scripts
- Include functions for loading data, performing analysis, and generating reports
- Save visualizations with descriptive names to `reports/figures/`
- Generate comprehensive markdown reports in `reports/findings/`

```python
# Example EDA script structure
if __name__ == "__main__":
    # 1. Load and prepare data
    data = load_data()
    
    # 2. Perform analysis
    results = analyze_data(data)
    
    # 3. Generate visualizations
    create_visualizations(results)
    
    # 4. Generate findings report
    generate_report(results)
```

### 6.4 Data Processing

⚠️ **Common Mistake**: Using Pandas instead of Polars, not handling missing data

✅ **Correct Approach**:
```python
import polars as pl

# Load data with Polars
data = pl.read_parquet(file_path)

# Handle missing values explicitly
data = data.filter(pl.col("team_id").is_not_null())

# Use Polars syntax for transformations
data = data.with_columns([
    pl.col("points").fill_null(0),
    (pl.col("fg_made") / pl.col("fg_attempted")).alias("fg_pct")
])
```

### 6.5 Pipeline Integration

⚠️ **Common Mistake**: Not following the stage-based pattern or ignoring configuration

✅ **Correct Approach**:
- Implement new processing as a pipeline stage
- Follow the existing logging and error handling patterns
- Respect configuration-driven behavior

### 6.6 File Paths

⚠️ **Common Mistake**: Using hardcoded paths or string concatenation

✅ **Correct Approach**:
```python
from pathlib import Path

# Get configuration
config = load_config("config/pipeline_config.yaml")
base_dir = Path(config.data.processed_dir)

# Construct paths properly
file_path = base_dir / category / f"{year}.parquet"
```

### 6.7 Error Handling

⚠️ **Common Mistake**: Not handling errors or using overly broad except clauses

✅ **Correct Approach**:
```python
try:
    data = pl.read_parquet(file_path)
except pl.exceptions.NoDataError:
    logger.error(f"File contains no data: {file_path}")
    return None
except Exception as e:
    logger.exception(f"Error loading data from {file_path}: {e}")
    raise
```

## 7. Code Examples

### 7.1 EDA Script Example

```python
"""
Regular Season vs Tournament Performance Analysis.

This script analyzes the differences between team performance in 
regular season games versus tournament games.
"""

import polars as pl
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, Any, Tuple

def load_data() -> Dict[str, pl.DataFrame]:
    """
    Load and prepare team box score data for analysis.
    
    Returns:
        Dictionary containing processed DataFrames
    """
    data_dir = Path("data/processed")
    
    # Load team box scores
    team_box = pl.read_parquet(data_dir / "team_box.parquet")
    
    # Load schedules to identify tournament games
    schedules = pl.read_parquet(data_dir / "schedules.parquet")
    
    return {"team_box": team_box, "schedules": schedules}

def analyze_data(data: Dict[str, pl.DataFrame]) -> Dict[str, Any]:
    """
    Perform analysis comparing regular season and tournament performance.
    
    Args:
        data: Dictionary containing processed DataFrames
        
    Returns:
        Dictionary containing analysis results
    """
    # Implementation of analysis
    # ...
    
    return results

def create_visualizations(results: Dict[str, Any]) -> Dict[str, str]:
    """
    Generate visualizations from analysis results.
    
    Args:
        results: Dictionary with analysis results
        
    Returns:
        Dictionary mapping visualization descriptions to file paths
    """
    figures_dir = Path("reports/figures")
    figures_dir.mkdir(exist_ok=True, parents=True)
    
    # Example visualization
    plt.figure(figsize=(10, 6))
    # Create plot using results...
    
    # Save figure
    fig_path = figures_dir / "regular_vs_tournament_efficiency.png"
    plt.savefig(fig_path)
    
    return {"efficiency_comparison": str(fig_path)}

def generate_report(results: Dict[str, Any], figures: Dict[str, str]) -> None:
    """
    Generate a markdown report of findings.
    
    Args:
        results: Dictionary with analysis results
        figures: Dictionary mapping visualization descriptions to file paths
    """
    findings_dir = Path("reports/findings")
    findings_dir.mkdir(exist_ok=True, parents=True)
    
    report_path = findings_dir / "regular_vs_tournament_analysis.md"
    
    with open(report_path, "w") as f:
        f.write("# Regular Season vs Tournament Performance Analysis\n\n")
        
        f.write("## Overview\n")
        f.write("This analysis examines how team performance differs between regular season and tournament games.\n\n")
        
        # Write remaining sections using template from reports/findings/README.md
        # ...

if __name__ == "__main__":
    # 1. Load and prepare data
    data = load_data()
    
    # 2. Perform analysis
    results = analyze_data(data)
    
    # 3. Generate visualizations
    figures = create_visualizations(results)
    
    # 4. Generate findings report
    generate_report(results, figures)
    
    print("Analysis complete. Report saved to reports/findings/regular_vs_tournament_analysis.md")
```

### 7.2 Data Loading Example

```python
def load_team_data(year: int, config: Config) -> pl.DataFrame:
    """
    Load team box score data for a specific season.
    
    Args:
        year: Season year (e.g., 2023)
        config: Pipeline configuration
        
    Returns:
        DataFrame with team statistics
    """
    # Construct file path
    data_dir = Path(config.data.raw_dir)
    file_path = data_dir / "team_box" / f"team_box_{year}.parquet"
    
    logger.info(f"Loading team data for {year} from {file_path}")
    
    try:
        # Define schema
        schema = {
            "game_id": pl.Int64,
            "team_id": pl.Int64,
            "team_name": pl.Utf8,
            "points": pl.Int32,
            # Other fields...
        }
        
        # Load data
        return pl.read_parquet(file_path, schema=schema)
    except Exception as e:
        logger.exception(f"Error loading team data for {year}: {e}")
        raise
```

### 7.3 Feature Engineering Example

> **Feature Structure**: For detailed information about feature organization, implementation requirements, and testing standards, refer to the [Feature Structure and Requirements](feature_structure.md) guide.

```python
def calculate_offensive_rating(team_stats: pl.DataFrame) -> pl.DataFrame:
    """
    Calculate offensive rating for teams based on points and possessions.
    
    Args:
        team_stats: DataFrame with team statistics
        
    Returns:
        DataFrame with added offensive_rating column
    """
    return team_stats.with_columns([
        (pl.col("points") * 100 / pl.col("possessions")).alias("offensive_rating")
    ])
```

## 8. Quick Reference

### Data Sources
- Repository: sportsdataverse/hoopR-mbb-data
- URL pattern: `https://github.com/sportsdataverse/hoopR-mbb-data/raw/refs/heads/main/mbb/{category}/parquet/{filename}_{YEAR}.parquet`
- Categories: play_by_play, player_box, schedules, team_box
- Years: 2003-2025

### Key File Paths
- Raw data: `data/raw/{category}/{year}.parquet`
- Processed data: `data/processed/{category}/{year}.parquet`
- Features: `data/features/{feature_set}/{year}.parquet`
- Models: `models/{model_type}/{model_name}.pt`
- Analysis reports: `reports/findings/{analysis_name}.md`
- Visualizations: `reports/figures/{viz_name}.{ext}`

### Important Libraries
- Data Processing: `polars` (not pandas)
- Deep Learning: `torch`
- Visualization: `plotly`, `matplotlib`, `seaborn`
- Configuration: `pyyaml`

### CLI Commands
```bash
# Full pipeline
python run_pipeline.py

# Run only specific stages
python run_pipeline.py --stages data features

# Process specific years
python run_pipeline.py --years 2023 2024

# Process specific categories
python run_pipeline.py --categories team_box player_box

# Calculate specific feature categories
python run_pipeline.py --stages features --feature-categories shooting team_performance

# Calculate specific features by ID
python run_pipeline.py --stages features --feature-ids S01 T01

# Overwrite existing feature data
python run_pipeline.py --stages features --overwrite-features

# Clean data before running
python run_pipeline.py --clean-raw  # Clean raw data
python run_pipeline.py --clean-all  # Clean all data

# Custom configuration
python run_pipeline.py --config custom_config.yaml

# Run EDA script
python -m src.eda.script_name
```